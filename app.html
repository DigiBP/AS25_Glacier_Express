<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Prescription Chatbot (Chat + Upload)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      background: #f3f4f6;
      margin: 0;
      padding: 0;
      display: flex;
      justify-content: center;
      align-items: center;
      min-height: 100vh;
    }

    .app {
      background: #ffffff;
      width: 100%;
      max-width: 900px;
      border-radius: 16px;
      box-shadow: 0 10px 30px rgba(0,0,0,0.08);
      display: grid;
      grid-template-columns: 1.5fr 1fr;
      overflow: hidden;
    }

    @media (max-width: 768px) {
      .app {
        grid-template-columns: 1fr;
        max-width: 100%;
        border-radius: 0;
      }
    }

    .chat-panel {
      border-right: 1px solid #e5e7eb;
      display: flex;
      flex-direction: column;
      height: 550px;
    }

    .panel-header {
      padding: 12px 16px;
      border-bottom: 1px solid #e5e7eb;
      display: flex;
      align-items: center;
      gap: 8px;
      background: #f9fafb;
    }

    .panel-header h1 {
      font-size: 16px;
      margin: 0;
    }

    .panel-header span {
      font-size: 12px;
      color: #6b7280;
    }

    .status-dot {
      width: 8px;
      height: 8px;
      border-radius: 999px;
      background: #22c55e;
      box-shadow: 0 0 0 4px rgba(34,197,94,0.2);
    }

    .chat-log {
      flex: 1;
      padding: 16px;
      overflow-y: auto;
      background: #f9fafb;
    }

    .message {
      max-width: 80%;
      margin-bottom: 10px;
      padding: 8px 12px;
      border-radius: 12px;
      font-size: 14px;
      line-height: 1.4;
      white-space: pre-wrap;
    }

    .message.user {
      margin-left: auto;
      background: #2563eb;
      color: #ffffff;
      border-bottom-right-radius: 4px;
    }

    .message.bot {
      margin-right: auto;
      background: #e5e7eb;
      color: #111827;
      border-bottom-left-radius: 4px;
    }

    .message.system {
      margin: 0 auto 10px auto;
      background: transparent;
      color: #6b7280;
      font-size: 12px;
      text-align: center;
    }

    .chat-input {
      padding: 10px 12px;
      border-top: 1px solid #e5e7eb;
      display: flex;
      gap: 8px;
      background: #ffffff;
    }

    .chat-input input[type="text"] {
      flex: 1;
      border-radius: 999px;
      border: 1px solid #d1d5db;
      padding: 8px 12px;
      font-size: 14px;
      outline: none;
    }

    .chat-input input[type="text"]:focus {
      border-color: #2563eb;
      box-shadow: 0 0 0 1px rgba(37,99,235,0.2);
    }

    .btn {
      border-radius: 999px;
      border: none;
      padding: 8px 14px;
      font-size: 14px;
      cursor: pointer;
      display: inline-flex;
      align-items: center;
      gap: 4px;
    }

    .btn-primary {
      background: #2563eb;
      color: #ffffff;
    }

    .btn-primary:disabled {
      background: #9ca3af;
      cursor: not-allowed;
    }

    .btn-secondary {
      background: #e5e7eb;
      color: #111827;
    }

    .right-panel {
      padding: 16px;
      display: flex;
      flex-direction: column;
      gap: 12px;
    }

    .right-panel h2 {
      font-size: 16px;
      margin: 0;
    }

    .right-panel p {
      font-size: 13px;
      color: #4b5563;
      margin: 0 0 4px 0;
    }

    .card {
      border-radius: 12px;
      border: 1px solid #e5e7eb;
      padding: 10px 12px;
      background: #f9fafb;
      font-size: 12px;
      max-height: 140px;
      overflow-y: auto;
      white-space: pre-wrap;
    }

    .file-input-row {
      display: flex;
      flex-direction: column;
      gap: 8px;
      margin-top: 4px;
    }

    .file-input-row input[type="file"] {
      font-size: 12px;
    }

    .small {
      font-size: 11px;
      color: #6b7280;
    }

    .tag {
      display: inline-flex;
      align-items: center;
      padding: 2px 8px;
      border-radius: 999px;
      background: #e0f2fe;
      color: #0369a1;
      font-size: 11px;
      margin-top: 4px;
    }
  </style>
</head>
<body>
<div class="app">
  <!-- LEFT: chat UI (uses Voiceflow DM API) -->
  <div class="chat-panel">
    <div class="panel-header">
      <div class="status-dot"></div>
      <div>
        <h1>Prescription Chatbot</h1>
        <span>Chat + Upload (Dev Version)</span>
      </div>
    </div>
    <div id="chat-log" class="chat-log"></div>
    <form id="chat-form" class="chat-input">
      <input id="user-input" type="text" placeholder="Type a message..." autocomplete="off" />
      <button type="submit" class="btn btn-primary" id="send-btn">Send</button>
    </form>
  </div>

  <!-- RIGHT: upload & OCR -->
  <div class="right-panel">
    <h2>Upload your prescription</h2>
    <p>
      Choose an image or PDF. The text will be extracted with OCR.space and sent
      into this same conversation automatically.
    </p>

    <div class="file-input-row">
      <input id="file-input" type="file" accept="image/*,.pdf" />
      <button id="upload-btn" class="btn btn-secondary" type="button">
        üìÑ Upload & Extract
      </button>
      <span class="small">
        Demo only: keys are in the front-end. For production, you‚Äôd put this behind a backend.
      </span>
    </div>

    <p>Last OCR result (for debugging):</p>
    <div id="ocr-result" class="card">No file processed yet.</div>

    <p class="small">
      This page talks directly to your <span class="tag">Voiceflow dev version</span>
      using a single <span class="tag">userId</span>, so chat and uploads share the same state.
    </p>
  </div>
</div>

<script>
  /***********************
   * üîë CONFIG ‚Äì EDIT THESE
   ***********************/
  const OCR_API_KEY = "K81489788688957";          // from ocr.space
  const VOICEFLOW_API_KEY = "VF.DM.69316a18ff10cea6369672b5.ZKAsbEJTPclbO10u";    // VF.DM.xxxxx
  const VOICEFLOW_VERSION_ID = "69285191ccd3669734e5a5c1"; // e.g. "69285191ccd3669734e5a5c1"
  const USER_ID = "student-demo-user";                   // any string; must be consistent

  console.log("‚úÖ Script loaded, using USER_ID:", USER_ID);

  /***********************
   * DOM elements
   ***********************/
  const chatLog = document.getElementById("chat-log");
  const userInput = document.getElementById("user-input");
  const chatForm = document.getElementById("chat-form");
  const sendBtn = document.getElementById("send-btn");
  const fileInput = document.getElementById("file-input");
  const uploadBtn = document.getElementById("upload-btn");
  const ocrResultBox = document.getElementById("ocr-result");

  function addMessage(sender, text, typeOverride) {
    const div = document.createElement("div");
    const cls =
      typeOverride ||
      (sender === "user" ? "message user" :
       sender === "bot"  ? "message bot"  : "message system");
    div.className = cls;
    div.textContent = text;
    chatLog.appendChild(div);
    chatLog.scrollTop = chatLog.scrollHeight;
  }

  function setLoading(isLoading) {
    sendBtn.disabled = isLoading;
    uploadBtn.disabled = isLoading;
  }

  /***********************
   * Voiceflow DM API
   ***********************/
  async function sendToVoiceflow(text) {
    setLoading(true);
    if (text) addMessage("user", text);

    console.log("‚û°Ô∏è Sending to Voiceflow‚Ä¶", { USER_ID, text });

    try {
      const response = await fetch(
        "https://general-runtime.voiceflow.com/state/user/" +
          encodeURIComponent(USER_ID) +
          "/interact",
        {
          method: "POST",
          headers: {
            "Authorization": VOICEFLOW_API_KEY,
            "Content-Type": "application/json",
            "versionID": VOICEFLOW_VERSION_ID
          },
          body: JSON.stringify({
            request: {
              type: "text",
              payload: text || ""
            }
          })
        }
      );

      console.log("üì• Voiceflow response status:", response.status);

      const traces = await response.json();
      console.log("üßæ Voiceflow traces:", traces);

      let anyReply = false;
      traces.forEach(trace => {
        if (trace.type === "text" || trace.type === "speak") {
          if (trace.payload && trace.payload.message) {
            addMessage("bot", trace.payload.message);
            anyReply = true;
          }
        }
      });

      if (!anyReply) {
        addMessage("system", "[No visible reply ‚Äì check your Voiceflow flow or trace types]");
      }
    } catch (err) {
      console.error("‚ùå Error talking to Voiceflow:", err);
      addMessage("system", "Error talking to Voiceflow. Check console and API key.");
    } finally {
      setLoading(false);
    }
  }

  /***********************
   * OCR.space
   ***********************/
  async function runOCR(file) {
    console.log("üü¶ runOCR() started with file:", file && file.name);
    const formData = new FormData();
    formData.append("file", file);
    formData.append("apikey", OCR_API_KEY);
    formData.append("language", "eng");
    formData.append("isTable", "true");
    formData.append("isOverlayRequired", "false");

    console.log("üì§ Sending OCR request to OCR.space‚Ä¶");

    const response = await fetch("https://api.ocr.space/parse/image", {
      method: "POST",
      body: formData
    });

    console.log("üì• OCR response status:", response.status);

    const data = await response.json();
    console.log("üßæ Parsed OCR JSON:", data);

    if (data.IsErroredOnProcessing) {
      throw new Error(data.ErrorMessage || "OCR processing error");
    }

    const firstResult =
      data.ParsedResults && data.ParsedResults.length > 0
        ? data.ParsedResults[0]
        : null;

    if (!firstResult || !firstResult.ParsedText) {
      throw new Error("No text found in OCR result");
    }

    return firstResult.ParsedText.trim();
  }

  /***********************
   * Event handlers
   ***********************/
  // Text chat
  chatForm.addEventListener("submit", async (e) => {
    e.preventDefault();
    const text = userInput.value.trim();
    if (!text) return;
    userInput.value = "";
    await sendToVoiceflow(text);
  });

  // Upload + OCR + send into conversation
  uploadBtn.addEventListener("click", async () => {
    const file = fileInput.files && fileInput.files[0];
    if (!file) {
      alert("Please choose an image or PDF first.");
      return;
    }

    setLoading(true);
    addMessage("system", "Uploading file and running OCR‚Ä¶");

    try {
      const text = await runOCR(file);
      ocrResultBox.textContent = text || "[Empty OCR result]";

      const wrappedMessage =
        "Here is my prescription information (from the upload button):\n\n" +
        text;

      await sendToVoiceflow(wrappedMessage);
    } catch (err) {
      console.error("‚ùå OCR error:", err);
      addMessage("system", "OCR failed. Check console / API key / file type.");
      ocrResultBox.textContent = "Error running OCR: " + err.message;
    } finally {
      setLoading(false);
    }
  });

  // Optional: send an initial launch message to start the flow
  (async function init() {
    addMessage("system", "Type below, or upload a prescription to begin.");
    // If you want to trigger a Launch request instead of empty text, you can adjust sendToVoiceflow
  })();
</script>
</body>
</html>
